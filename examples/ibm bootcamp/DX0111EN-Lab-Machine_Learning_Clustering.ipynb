{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cognitiveclass.ai\"><img src = \"https://ibm.box.com/shared/static/9gegpsmnsoo25ikkbl4qzlvlyjbgxs5x.png\" width = 400> </a>\n",
    "\n",
    "<h1 align=center><font size = 5>Machine Learning - Clustering</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<h2> Table of Contents</h2>  \n",
    "<font size = 3>\n",
    "1. <a href=\"#item1\">Manual Simulation of *k*-means on 2-D Data</a>  \n",
    "2. <a href=\"#item2\">Cluster Real Data Usin *k*-means</a>  \n",
    "2.1 <a href=\"#item3\">Download and Explore Customer Data</a>     \n",
    "2.2 <a href=\"#item4\">Preprocess Data</a>   \n",
    "2.3 <a href=\"#item5\">Cluster Data Using *k*-means</a>  \n",
    "2.4 <a href=\"#item6\">Get Most Popular Products in Each Cluster</a>      \n",
    "</font>\n",
    "<br>\n",
    "<p></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Manual Simulation of *k*-means on 2-D Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print('Libraries imported!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 30 data points belonging to 2 different clusters (x1 is the first feature and x2 is the second feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "x1 = [-4.9, -3.5, 0, -4.5, -3, -1, -1.2, -4.5, -1.5, -4.5, -1, -2, -2.5, -2, -1.5, 4, 1.8, 2, 2.5, 3, 4, 2.25, 1, 0, 1, 2.5, 5, 2.8, 2, 2]\n",
    "x2 = [-3.5, -4, -3.5, -3, -2.9, -3, -2.6, -2.1, 0, -0.5, -0.8, -0.8, -1.5, -1.75, -1.75, 0, 0.8, 0.9, 1, 1, 1, 1.75, 2, 2.5, 2.5, 2.5, 2.5, 3, 6, 6.5]\n",
    "\n",
    "print('Datapoints defined!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a function that carries out the cluster assignment step of each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_map = np.array(['b', 'r'])\n",
    "def assign_members(x1, x2, centers):\n",
    "    compare_to_first_center = np.sqrt(np.square(np.array(x1) - centers[0][0]) + np.square(np.array(x2) - centers[0][1]))\n",
    "    compare_to_second_center = np.sqrt(np.square(np.array(x1) - centers[1][0]) + np.square(np.array(x2) - centers[1][1]))\n",
    "    class_of_points = compare_to_first_center > compare_to_second_center\n",
    "    colors = colors_map[class_of_points + 1 - 1]\n",
    "    return colors, class_of_points\n",
    "\n",
    "print('assign_members function defined!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a function that carries out the centroid move step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update means\n",
    "def update_centers(x1, x2, class_of_points):\n",
    "    center1 = [np.mean(np.array(x1)[~class_of_points]), np.mean(np.array(x2)[~class_of_points])]\n",
    "    center2 = [np.mean(np.array(x1)[class_of_points]), np.mean(np.array(x2)[class_of_points])]\n",
    "    return [center1, center2]\n",
    "\n",
    "print('assign_members function defined!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a function that plots the data points along with the cluster centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_points(centroids=None, colors=\"g\", figure_title=None):\n",
    "    # plot the figure\n",
    "    fig = plt.figure(figsize=(15, 10))  # create a figure object\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    \n",
    "    centroid_colors = [\"bx\", \"rx\"]\n",
    "    if centroids:\n",
    "        for (i, centroid) in enumerate(centroids):\n",
    "            ax.plot(centroid[0], centroid[1], centroid_colors[i], markeredgewidth=5, markersize=20)\n",
    "    plt.scatter(x1, x2, s=500, c=colors)\n",
    "    \n",
    "    # define the ticks\n",
    "    xticks = np.linspace(-6, 8, 15, endpoint=True)\n",
    "    yticks = np.linspace(-6, 6, 13, endpoint=True)\n",
    "\n",
    "    # fix the horizontal axis\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_yticks(yticks)\n",
    "\n",
    "    # add tick labels\n",
    "    xlabels = xticks\n",
    "    ax.set_xticklabels(xlabels)\n",
    "    ylabels = yticks\n",
    "    ax.set_yticklabels(ylabels)\n",
    "\n",
    "    # style the ticks\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.tick_params('both', length=2, width=1, which='major', labelsize=15)\n",
    "    \n",
    "    # add labels to axes\n",
    "    ax.set_xlabel('x1', fontsize=20)\n",
    "    ax.set_ylabel('x2', fontsize=20)\n",
    "    \n",
    "    # add title to figure\n",
    "    ax.set_title(figure_title, fontsize=24)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "print('plot_points function defined!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize K-means - plot data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_points(figure_title='Scatter Plot of x2 vs x1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize K-means - randomly define clusters and add them to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = [[-2, 2], [2, -2]]\n",
    "plot_points(centers, figure_title='k-means Initialization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run K-means (4-iterations only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "number_of_iterations = 4\n",
    "for i in range(number_of_iterations):\n",
    "    input(\"Iteration {} - Press Enter to update the members of each cluster\".format(i+1))\n",
    "    colors, class_of_points = assign_members(x1, x2, centers)\n",
    "    title = \"Iteration {} - Cluster Assignment\".format(i+1)\n",
    "    plot_points(centers, colors, figure_title=title)\n",
    "    input(\"Iteration {} - Press Enter to update the centers\".format(i+1))\n",
    "    centers = update_centers(x1, x2, class_of_points)\n",
    "    title = \"Iteration {} - Centroid Move\".format(i+1)\n",
    "    plot_points(centers, colors, figure_title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power of Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.cluster import KMeans    \n",
    "\n",
    "kmeans = KMeans(n_clusters=2, max_iter=300, random_state=0).fit(X)     \n",
    "kmeans.labels_\n",
    "\n",
    "kmeans.cluster_centers_      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cluster Real Data Using *k*-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd # library for data analsysis\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import numpy as np # library to handle data in a vectorized manner\n",
    "import scipy # scientific computing library\n",
    "    \n",
    "# import k-means from scikit-learn\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Download and Explore Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download data from IBM server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data from IBM server\n",
    "!wget -O customers_data.csv --quiet https://ibm.box.com/shared/static/albv617gy292tmqljaacbqm0mz62tiz2.csv\n",
    "    \n",
    "print('Data Downloaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data into a *pandas* dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_data = pd.read_csv('customers_data.csv')\n",
    "\n",
    "# print the size of the dataset\n",
    "print(customers_data.shape)\n",
    "\n",
    "# display first five rows of dataframe\n",
    "customers_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many customers are in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_customers = len(customers_data['CUST_ID'].unique())\n",
    "print('There are {} customers'.format(num_customers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's fix the gender code in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first check what values exist in the `GenderCode` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_data['GenderCode'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's replace `Mr.` and `Master` with `Male`, and `Mrs.` and `Miss` with `Female`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_data = customers_data['GenderCode']\n",
    "gender_data[gender_data.isin(['Mr.', 'Master.'])] = 'Male'\n",
    "gender_data[gender_data.isin(['Mrs.', 'Miss.'])] = 'Female'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the updated dataframe to make sure that everything looks fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It looks like transactions of customers where labelled as low, medium, or high in value. Let's explore that a little"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that no other values exist in the `ORDER_TYPE` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_data['ORDER_TYPE'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's explore the transactions labelled as `LowValue`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's get all the data instances pertaining to this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_value = customers_data.loc[customers_data['ORDER_TYPE'] == 'LowValue']\n",
    "low_value.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's see how many instances exist in the dataframe and get the minimum and the maximum values in this bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(low_value.shape)\n",
    "print(min(low_value['ORDER_VALUE']), max(low_value['ORDER_VALUE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's do the same thing to `MediumValue`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the data instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_value = customers_data.loc[customers_data['ORDER_TYPE'] == 'MediumValue']\n",
    "medium_value.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print how many instances exist in the dataframe and get the minimum and the maximum values in this bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(medium_value.shape)\n",
    "print(min(medium_value['ORDER_VALUE']), max(medium_value['ORDER_VALUE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And Let's do that again to `HighValue`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_value = customers_data.loc[customers_data['ORDER_TYPE'] == 'HighValue']\n",
    "high_value.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print how many instances exist in the dataframe and get the minimum and the maximum values in this bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(high_value.shape)\n",
    "print(min(high_value['ORDER_VALUE']), max(high_value['ORDER_VALUE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's save the products names in a variable called `products`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = customers_data.columns.values[7:customers_data.shape[1]]\n",
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see if there is a gender pattern in those whose transactions where labelled `LowValue`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = low_value['CUST_ID'].unique() # get a list of the customers\n",
    "\n",
    "# define lists to save the minimum, avergae, and maximum trasaction values for each male customer\n",
    "male_min = []\n",
    "male_avg = []\n",
    "male_max = []\n",
    "\n",
    "# define lists to save the minimum, avergae, and maximum trasaction values for each female customer\n",
    "female_min = []\n",
    "female_avg = []\n",
    "female_max = []\n",
    "\n",
    "# loop through customers and compute the statistics\n",
    "for customer in customers:\n",
    "    customer_data = low_value[low_value['CUST_ID'] == customer]\n",
    "    customer_data.reset_index(inplace=True, drop=True)\n",
    "    if customer_data.loc[0, 'GenderCode'] == 'Male':\n",
    "        male_min.append(min(customer_data['ORDER_VALUE']))\n",
    "        male_avg.append(np.mean(customer_data['ORDER_VALUE']))\n",
    "        male_max.append(max(customer_data['ORDER_VALUE']))\n",
    "        \n",
    "    else:\n",
    "        female_min.append(min(customer_data['ORDER_VALUE']))\n",
    "        female_avg.append(np.mean(customer_data['ORDER_VALUE']))\n",
    "        female_max.append(max(customer_data['ORDER_VALUE']))\n",
    "        \n",
    "print('Male and female lists populated!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print statistics for male cutomers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Males:\\n', 'Min: {}\\n'.format(np.min(male_min)), 'Avg: {}\\n'.format(np.mean(male_avg)), 'Max: {}\\n'.format(np.max(male_max)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print statistics for female cutomers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Females:', 'Min: {}\\n'.format(np.min(female_min)), 'Avg: {}\\n'.format(np.mean(female_avg)), 'Max: {}\\n'.format(np.max(female_max)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's define a function that returns the summary of customers so we can repeat the same analysis for `MediumValue` and `HighValue`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_summary_customers(dataframe):\n",
    "    customers = dataframe['CUST_ID'].unique()\n",
    "\n",
    "    male_min = []\n",
    "    male_avg = []\n",
    "    male_max = []\n",
    "\n",
    "    female_min = []\n",
    "    female_avg = []\n",
    "    female_max = []\n",
    "\n",
    "    for customer in customers:\n",
    "        customer_data = dataframe.loc[dataframe['CUST_ID'] == customer]\n",
    "        customer_data.reset_index(inplace=True, drop=True)\n",
    "        if customer_data.loc[0, 'GenderCode'] == 'Male':\n",
    "            male_min.append(min(customer_data['ORDER_VALUE']))\n",
    "            male_avg.append(np.mean(customer_data['ORDER_VALUE']))\n",
    "            male_max.append(max(customer_data['ORDER_VALUE']))\n",
    "        \n",
    "        else:\n",
    "            female_min.append(min(customer_data['ORDER_VALUE']))\n",
    "            female_avg.append(np.mean(customer_data['ORDER_VALUE']))\n",
    "            female_max.append(max(customer_data['ORDER_VALUE']))\n",
    "    \n",
    "    print('Males:\\n', 'Min: {}\\n'.format(np.min(male_min)), 'Avg: {}\\n'.format(np.mean(male_avg)), 'Max: {}\\n'.format(np.max(male_max)))\n",
    "    print('Females:\\n', 'Min: {}\\n'.format(np.min(female_min)), 'Avg: {}\\n'.format(np.mean(female_avg)), 'Max: {}\\n'.format(np.max(female_max)))\n",
    "\n",
    "print('return_summary_customers function defined!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_summary_customers(medium_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_summary_customers(high_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: No difference between male and female customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recall how the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's drop all columns except the customer ID column and the products columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_purchase_data = customers_data.iloc[:, [0] + list(range(7, customers_data.shape[1]))]\n",
    "customers_purchase_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's group data pertaining to each customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = customers_purchase_data.groupby('CUST_ID').sum().reset_index()\n",
    "grouped_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For clustering, we only need the data pertaining to what was purchased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchased_data = grouped_data.iloc[:, 1:]\n",
    "purchased_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**. It is important to normalize the data whenever you are building a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the mean of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_means = purchased_data.mean(axis=0)\n",
    "col_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the standard deviation of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_stds = purchased_data.std(axis=0)\n",
    "col_stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize the data by subtracting the mean from each column and dividing by the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_purchased_data = (purchased_data - col_means) / col_stds\n",
    "norm_purchased_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do a quick sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_purchased_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Cluster Data Using *k*-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's use _scikit-learn_ implementation of *k*-means to break the dataset into 100 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=100, random_state=0).fit(norm_purchased_data)\n",
    "print('Clustering process is complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans.labels_ # the generated labels\n",
    "cluster_centroids = kmeans.cluster_centers_ # the centroids of the clusters that emerged\n",
    "\n",
    "print('First five labels {}'.format(labels[0:5]))\n",
    "print('First five centroid {}'.format(cluster_centroids[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that the right number of labels was returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add labels to grouped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data_w_labels = grouped_data\n",
    "grouped_data_w_labels['labels'] = labels\n",
    "grouped_data_w_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's examine how many members are in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster_num in np.arange(100):\n",
    "    cluster_data = grouped_data_w_labels[grouped_data_w_labels['labels'] == cluster_num]\n",
    "    print('Cluster {}: {} data points'.format(cluster_num, cluster_data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's check out the cluster with the highest number of members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = grouped_data_w_labels[grouped_data_w_labels['labels'] == 6]\n",
    "cluster_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Get Most Popular Products in Each Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's sort the products in each cluster in descending order of quantity purchased by customers in cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's group the data by labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_purchased_data = grouped_data_w_labels.iloc[:, 1:].groupby('labels').sum().reset_index()\n",
    "grouped_purchased_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define a function that returns the products sorted in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_most_popular_products(row):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values\n",
    "\n",
    "print('return_most_populat_products function defined!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, Let's define the columns for our new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create columns according to number of top venues\n",
    "columns = ['labels']\n",
    "for ind in np.arange(len(grouped_purchased_data.columns.values[1:])):\n",
    "    columns.append('Most Popular Product {}'.format(ind+1))\n",
    "    \n",
    "print('columns created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's define the datafame and fill in each row by applying the `return_most_popular_products` function to the `grouped_purchased_data` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe\n",
    "grouped_purchased_data_sorted = pd.DataFrame(columns=columns)\n",
    "grouped_purchased_data_sorted['labels'] = grouped_purchased_data['labels']\n",
    "\n",
    "for ind in np.arange(grouped_purchased_data.shape[0]):\n",
    "    grouped_purchased_data_sorted.iloc[ind, 1:] = return_most_popular_products(grouped_purchased_data.iloc[ind, :])\n",
    "\n",
    "grouped_purchased_data_sorted.head() # display the products for first 5 clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank you for completing this lab!\n",
    "\n",
    "This notebook was created by [Alex Aklson](https://www.linkedin.com/in/aklson/). I hope you found this lab interesting and educational. Feel free to contact me if you have any questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to learn more?\n",
    "\n",
    "You can take free [Python for Data Science](http://cocl.us/DX0111EN_PY0101EN) or [Data Analysis with Python](http://cocl.us/DX0111EN_DA0101EN) or [Data Visualization with Python](http://cocl.us/DX0111EN_DV0101EN) courses.  \n",
    "\n",
    "Also, you can use Data Science Experience to run these notebooks faster with bigger datasets. Data Science Experience (DSX) is IBM's leading cloud solution for data scientists, built by data scientists. With Jupyter notebooks, RStudio, Apache Spark and popular libraries pre-packaged in the cloud, DSX enables data scientists to collaborate on their projects without having to install anything. Join the fast-growing community of DSX users today with a free account at [Data Science Experience](http://cocl.us/DX0111EN_DSX)This is the end of this lesson. Hopefully, now you have a deeper and intuitive understanding regarding the LSTM model. Thank you for reading this notebook, and good luck on your studies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright &copy; 2018 [Cognitive Class](https://cognitiveclass.ai/). This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
